# -*- coding: utf-8 -*-
"""chatbot RAYA fake.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1a0vDP29e5rZC3NWwvC6_52NcZ-P7HzKu
"""

import streamlit as st
import pandas as pd
import numpy as np
from langchain_groq import ChatGroq
from langchain_core.messages import SystemMessage, HumanMessage
from langchain.chains import ConversationChain
from langchain.memory import ConversationBufferMemory
import json
import re
from io import BytesIO

# Set page config
st.set_page_config(
    page_title="Financial Data Assistant",
    page_icon="📊",
    layout="wide"
)

# Initialize session state
if 'df' not in st.session_state:
    st.session_state.df = None
if 'data_summary' not in st.session_state:
    st.session_state.data_summary = None
if 'chat_history' not in st.session_state:
    st.session_state.chat_history = []
if 'conversation' not in st.session_state:
    st.session_state.conversation = None
if 'file_name' not in st.session_state:
    st.session_state.file_name = None

def get_data_summary(df):
    """Generate a comprehensive summary of the loaded data for the AI assistant"""
    summary = {
        "shape": df.shape,
        "columns": list(df.columns),
        "data_types": df.dtypes.to_dict(),
        "sample_data": df.head(3).to_dict(),
        "numeric_columns": df.select_dtypes(include=[np.number]).columns.tolist(),
        "missing_values": df.isnull().sum().to_dict()
    }

    # Get unique values for categorical columns
    categorical_info = {}
    for col in df.select_dtypes(include=['object']).columns:
        unique_values = df[col].unique()
        categorical_info[col] = {
            'unique_count': len(unique_values),
            'unique_values': unique_values.tolist()[:20]  # Show first 20 values
        }

    summary['categorical_info'] = categorical_info

    # Financial metrics structure analysis
    financial_metrics = {}

    # Analyze the data structure
    if 'Entity' in df.columns:
        financial_metrics['entities'] = df['Entity'].unique().tolist()
        financial_metrics['entity_count'] = len(df['Entity'].unique())

    if 'Category' in df.columns:
        financial_metrics['categories'] = df['Category'].unique().tolist()
        financial_metrics['category_count'] = len(df['Category'].unique())

    if 'Month' in df.columns:
        financial_metrics['months'] = df['Month'].unique().tolist()
        financial_metrics['month_count'] = len(df['Month'].unique())

    # Year columns (numeric columns that look like years)
    year_columns = [col for col in df.columns if str(col).isdigit() and 2000 <= int(col) <= 2030]
    if year_columns:
        financial_metrics['year_columns'] = year_columns

    summary['financial_metrics'] = financial_metrics
    return summary

def analyze_financial_query(query, df, data_summary):
    """Analyze financial data based on user query with advanced filtering"""

    query_lower = query.lower()
    results = {}

    try:
        # Extract potential filters from query
        filters = extract_query_filters(query)

        # Apply filters to dataframe
        filtered_df = apply_filters(df, filters)

        results['query_interpretation'] = {
            'original_query': query,
            'filters_extracted': filters,
            'filtered_rows': len(filtered_df),
            'total_rows': len(df)
        }

        if len(filtered_df) == 0:
            # Provide helpful suggestions
            available_entities = df['Entity'].unique().tolist() if 'Entity' in df.columns else []
            available_categories = df['Category'].unique().tolist() if 'Category' in df.columns else []

            results['no_data_found'] = {
                'message': "No data found matching your criteria.",
                'suggestions': {
                    'available_entities': available_entities[:10],  # Show first 10
                    'available_categories': available_categories,
                    'available_years': [col for col in df.columns if str(col).isdigit()]
                }
            }
            return results

        # Show sample of filtered data for transparency
        results['filtered_data_preview'] = {
            'sample_rows': filtered_df.head(3).to_dict('records'),
            'showing': f"{min(3, len(filtered_df))} of {len(filtered_df)} matching rows"
        }

        # Determine what metric to calculate based on query
        metric_requested = determine_metric_from_query(query_lower)
        results['metric_requested'] = metric_requested

        # Calculate based on the data structure (years as columns)
        year_columns = [col for col in filtered_df.columns if str(col).isdigit() and 2000 <= int(col) <= 2030]

        if year_columns:
            # Calculate for each year column
            for year_col in year_columns:
                if year_col in filtered_df.columns:
                    year_data = filtered_df[year_col].dropna()
                    if len(year_data) > 0:
                        results[f'{year_col}_metrics'] = {
                            'total': float(year_data.sum()),
                            'average': float(year_data.mean()),
                            'count': len(year_data),
                            'max': float(year_data.max()),
                            'min': float(year_data.min())
                        }

        # Group by analysis if multiple entities/categories
        if len(filtered_df) > 1:
            results['detailed_breakdown'] = perform_detailed_breakdown(filtered_df, query)

        # Summary statistics for the filtered data
        if any(term in query_lower for term in ['summary', 'overview', 'describe', 'statistics', 'all']):
            numeric_cols = filtered_df.select_dtypes(include=[np.number]).columns
            if len(numeric_cols) > 0:
                results['summary_statistics'] = filtered_df[numeric_cols].describe().to_dict()

    except Exception as e:
        results['error'] = f"Error analyzing data: {str(e)}"
        results['debug_info'] = {
            'query': query,
            'dataframe_shape': df.shape,
            'columns': df.columns.tolist()
        }

    return results

def determine_metric_from_query(query_lower):
    """Determine what financial metric the user is asking for"""
    if any(term in query_lower for term in ['revenue', 'sales', 'income', 'turnover']):
        return 'revenue'
    elif any(term in query_lower for term in ['profit', 'earnings', 'ebitda', 'ebit']):
        return 'profit'
    elif any(term in query_lower for term in ['total', 'sum']):
        return 'total'
    elif any(term in query_lower for term in ['average', 'mean']):
        return 'average'
    else:
        return 'general'

def perform_detailed_breakdown(dataframe, query):
    """Perform detailed breakdown analysis"""
    breakdown = {}

    # Group by Entity if available
    if 'Entity' in dataframe.columns:
        entity_breakdown = {}
        for entity in dataframe['Entity'].unique():
            entity_data = dataframe[dataframe['Entity'] == entity]
            year_cols = [col for col in entity_data.columns if str(col).isdigit()]

            entity_totals = {}
            for year_col in year_cols:
                if year_col in entity_data.columns:
                    total = entity_data[year_col].sum()
                    entity_totals[year_col] = float(total)

            entity_breakdown[entity] = entity_totals

        breakdown['by_entity'] = entity_breakdown

    # Group by Category if available
    if 'Category' in dataframe.columns:
        category_breakdown = {}
        for category in dataframe['Category'].unique():
            category_data = dataframe[dataframe['Category'] == category]
            year_cols = [col for col in category_data.columns if str(col).isdigit()]

            category_totals = {}
            for year_col in year_cols:
                if year_col in category_data.columns:
                    total = category_data[year_col].sum()
                    category_totals[year_col] = float(total)

            category_breakdown[category] = category_totals

        breakdown['by_category'] = category_breakdown

    return breakdown

def extract_query_filters(query):
    """Extract filtering criteria from user query"""
    filters = {}
    query_lower = query.lower()

    # Extract years (2020-2030)
    years = re.findall(r'\b(20[0-3][0-9])\b', query)
    if years:
        filters['years'] = years

    # Extract common product/category terms
    words = query.split()
    potential_categories = []

    for word in words:
        # Look for uppercase words or specific patterns that might be categories/products
        cleaned_word = word.strip('.,!?()[]{}":;')
        if (cleaned_word.isupper() and len(cleaned_word) > 1) or \
           (cleaned_word.isalnum() and len(cleaned_word) > 2 and not cleaned_word.lower() in
            ['the', 'and', 'for', 'total', 'revenue', 'profit', 'sales', 'what', 'show', 'give', 'calculate']):
            potential_categories.append(cleaned_word)

    if potential_categories:
        filters['categories'] = potential_categories

    # Extract specific filter words
    filter_indicators = ['of', 'for', 'in', 'from', 'where', 'with']
    for indicator in filter_indicators:
        if indicator in query_lower:
            # Get words after the indicator
            parts = query_lower.split(indicator)
            if len(parts) > 1:
                after_indicator = parts[1].strip()
                # Extract meaningful terms
                terms = [term.strip('.,!?()[]{}":;') for term in after_indicator.split()
                        if len(term.strip('.,!?()[]{}":;')) > 1]
                if terms:
                    if 'filter_terms' not in filters:
                        filters['filter_terms'] = []
                    filters['filter_terms'].extend(terms[:3])  # Limit to 3 terms

    return filters

def apply_filters(dataframe, filters):
    """Apply extracted filters to the dataframe"""
    filtered_df = dataframe.copy()

    if not filters:
        return filtered_df

    # Apply entity/category filters
    all_filter_terms = []
    if 'categories' in filters:
        all_filter_terms.extend(filters['categories'])
    if 'filter_terms' in filters:
        all_filter_terms.extend(filters['filter_terms'])

    if all_filter_terms:
        # Create masks for each filter term
        masks = []

        for term in all_filter_terms:
            term_mask = pd.Series([False] * len(filtered_df), index=filtered_df.index)

            # Check Entity column
            if 'Entity' in filtered_df.columns:
                entity_mask = filtered_df['Entity'].astype(str).str.contains(term, case=False, na=False)
                term_mask = term_mask | entity_mask

            # Check Category column
            if 'Category' in filtered_df.columns:
                category_mask = filtered_df['Category'].astype(str).str.contains(term, case=False, na=False)
                term_mask = term_mask | category_mask

            # Check other text columns
            for col in filtered_df.select_dtypes(include=['object']).columns:
                if col not in ['Entity', 'Category']:
                    col_mask = filtered_df[col].astype(str).str.contains(term, case=False, na=False)
                    term_mask = term_mask | col_mask

            if term_mask.any():
                masks.append(term_mask)

        # Combine all masks with AND (all terms must match)
        if masks:
            final_mask = masks[0]
            for mask in masks[1:]:
                final_mask = final_mask & mask
            filtered_df = filtered_df[final_mask]

    return filtered_df

def initialize_chat_model(api_key):
    """Initialize the chat model with API key"""
    try:
        chat_model = ChatGroq(
            groq_api_key=api_key,
            model_name="llama3-70b-8192"
        )
        return chat_model
    except Exception as e:
        st.error(f"Error initializing chat model: {str(e)}")
        return None

def create_system_message(file_name, data_summary):
    """Create system message for the AI assistant"""
    return SystemMessage(
        content=f"""
        You are a financial data assistant with access to an Excel spreadsheet.

        SPREADSHEET INFORMATION:
        - File: {file_name}
        - Shape: {data_summary['shape'][0]} rows, {data_summary['shape'][1]} columns
        - Columns: {', '.join(data_summary['columns'])}

        DATA STRUCTURE:
        - Available Entities: {', '.join(data_summary['financial_metrics'].get('entities', [])[:10])}{"..." if len(data_summary['financial_metrics'].get('entities', [])) > 10 else ""}
        - Available Categories: {', '.join(data_summary['financial_metrics'].get('categories', []))}
        - Available Years: {', '.join(map(str, data_summary['financial_metrics'].get('year_columns', [])))}
        - Months: {', '.join(data_summary['financial_metrics'].get('months', []))}

        IMPORTANT: The years (2024, 2023, etc.) are COLUMN NAMES, not row values.
        The data structure is: Entity | Category | Month | 2024 | 2023 | 2022 | etc.

        When users ask for specific entities, use the EXACT entity names from the available entities list.
        Common entity examples: {', '.join(data_summary['financial_metrics'].get('entities', [])[:5])}

        You ONLY answer questions related to:
        - Financial analysis of the loaded data
        - Revenue, Profit, and other financial metrics from specific entities
        - Year-over-year comparisons using the year columns
        - Entity-specific financial data
        - Category-specific analysis (Revenue, Net Profit, etc.)
        - Monthly breakdowns and trends

        When answering:
        1. Always reference the actual data and specify which entities/categories were analyzed
        2. Provide specific numbers and calculations from the filtered data
        3. If no data matches the query, suggest similar available entities or categories
        4. Explain what filters were applied to get the results
        5. Use exact entity names and categories from the dataset

        If the user asks something unrelated to financial analysis or the spreadsheet data, reply:
        'Sorry, I only provide financial and Excel-related advice based on your uploaded data.'
        """
    )

def main():
    st.title("📊 Financial Data Assistant")
    st.markdown("Upload your Excel file and ask questions about your financial data!")

    # ---------------- Sidebar Section ----------------
    with st.sidebar:
        st.header("⚙️ Configuration")

        # Hardcoded API key for testing
        api_key = "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"
        st.success("✅ API Key is hardcoded for testing")

        if api_key:
            st.success("✅ API Key provided")
        else:
            st.warning("⚠️ Please enter your Groq API key to continue")

        st.markdown("---")
        st.header("📁 Upload Data")

    # ✅ File uploader must be outside the sidebar to avoid scope issues
    uploaded_file = st.file_uploader(
        "Choose an Excel file",
        type=['xlsx', 'xls'],
        help="Upload your financial Excel file"
    )

    # ---------------- Main Content Section ----------------
    col1, col2 = st.columns([2, 1])

    with col1:
        if uploaded_file is not None:
            try:
                df = pd.read_excel(uploaded_file)
                st.session_state.df = df
                st.session_state.file_name = uploaded_file.name
                st.session_state.data_summary = get_data_summary(df)

                st.success(f"✅ Loaded file: {uploaded_file.name}")
                st.info(f"📋 Shape: {df.shape[0]} rows, {df.shape[1]} columns")

                # Preview data
                with st.expander("🔍 Data Preview", expanded=False):
                    st.dataframe(df.head())

                # Data summary
                with st.expander("📊 Data Summary", expanded=False):
                    if 'Entity' in df.columns:
                        st.write(f"**Entities:** {len(df['Entity'].unique())} unique")
                        st.write(f"Sample entities: {', '.join(df['Entity'].unique()[:5])}")

                    if 'Category' in df.columns:
                        st.write(f"**Categories:** {', '.join(df['Category'].unique())}")

                    year_columns = [col for col in df.columns if str(col).isdigit() and 2000 <= int(col) <= 2030]
                    if year_columns:
                        st.write(f"**Available Years:** {', '.join(map(str, year_columns))}")

            except Exception as e:
                st.error(f"❌ Error loading file: {str(e)}")

        # ---------------- Chat Section ----------------
        if st.session_state.df is not None and api_key:
            st.markdown("---")
            st.header("💬 Chat with your Financial Data")

            # Initialize LLM model and conversation
            if st.session_state.conversation is None:
                chat_model = initialize_chat_model(api_key)
                if chat_model:
                    memory = ConversationBufferMemory(return_messages=True)
                    st.session_state.conversation = ConversationChain(
                        memory=memory,
                        llm=chat_model,
                        verbose=False
                    )

            # Display previous messages
            for user_msg, bot_msg in st.session_state.chat_history:
                with st.chat_message("user"):
                    st.write(user_msg)
                with st.chat_message("assistant"):
                    st.write(bot_msg)

            # New user input
            user_input = st.chat_input("Ask a question about your financial data...")

            if user_input and st.session_state.conversation:
                with st.chat_message("user"):
                    st.write(user_input)

                with st.chat_message("assistant"):
                    with st.spinner("Analyzing your data..."):
                        try:
                            analysis_results = analyze_financial_query(
                                user_input,
                                st.session_state.df,
                                st.session_state.data_summary
                            )

                            data_context = f"\n\nDATA ANALYSIS RESULTS:\n{json.dumps(analysis_results, indent=2, default=str)}"
                            enhanced_query = f"{user_input}{data_context}"

                            system_message = create_system_message(
                                st.session_state.file_name,
                                st.session_state.data_summary
                            )

                            messages = [system_message, HumanMessage(content=enhanced_query)]
                            response = st.session_state.conversation.llm.invoke(messages)

                            st.write(response.content)
                            st.session_state.chat_history.append((user_input, response.content))

                        except Exception as e:
                            st.error(f"❌ Error processing query: {str(e)}")

            # Clear chat history
            if st.button("🗑️ Clear Chat History"):
                st.session_state.chat_history = []
                st.rerun()




if __name__ == "__main__":
    main()

